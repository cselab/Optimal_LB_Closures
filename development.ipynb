{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import json\n",
    "from functools import partial\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from tianshou.utils import WandbLogger\n",
    "from tianshou.data import Batch, Collector, ReplayBuffer, VectorReplayBuffer\n",
    "from tianshou.env import DummyVectorEnv\n",
    "from tianshou.policy import BasePolicy, PPOPolicy\n",
    "from tianshou.trainer import OnpolicyTrainer\n",
    "from tianshou.utils.net.common import ActorCritic, Net\n",
    "#from tianshou.utils.net.discrete import Actor, Critic\n",
    "from tianshou.utils.net.continuous import Actor, Critic, ActorProb\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.wrappers import TimeLimit, RescaleAction, TransformObservation\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "from lib.environments import get_environment\n",
    "from lib.environments.kolmogorov import KolmogorovEnvironment\n",
    "from lib.policy import get_rl_algo\n",
    "from lib.distributions import ElementwiseNormal\n",
    "from lib.models import get_actor_critic\n",
    "from lib.utils import str2bool, Config, dict_to_wandb_table, restrict_to_num_threads\n",
    "from lib.trainer import MyOnpolicyTrainer\n",
    "\n",
    "#temporary solution for xlb imports\n",
    "sys.path.append(os.path.abspath('/home/pfischer/XLB'))\n",
    "#from my_flows.kolmogorov_2d import Kolmogorov_flow\n",
    "from my_flows.helpers import get_kwargs\n",
    "\n",
    "import wandb\n",
    "wandb.require(\"core\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args() -> argparse.Namespace:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--task\", type=str, default=\"CartPole-v1\")\n",
    "    parser.add_argument(\"--model\", type=str, default=\"ppo\")\n",
    "    parser.add_argument(\"--reward_threshold\", type=int, default=500)\n",
    "    parser.add_argument(\"--seed\", type=int, default=0)\n",
    "    parser.add_argument(\"--buffer_size\", type=int, default=5000)\n",
    "    parser.add_argument(\"--max_epoch\", type=int, default=20)\n",
    "    parser.add_argument(\"--step_per_epoch\", type=int, default=1000)\n",
    "    parser.add_argument(\"--train_num\", type=int, default=1)\n",
    "    parser.add_argument(\"--test_num\", type=int, default=1)\n",
    "    parser.add_argument(\"--logdir\", type=str, default=\"log\")\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.97)\n",
    "    parser.add_argument(\"--lr\", help='learning rate', type=float, default=0.0003)\n",
    "    parser.add_argument(\"--repeat_per_collect\", type=int, default=10)\n",
    "    parser.add_argument(\"--episode_per_test\", type=int, default=1)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=32)\n",
    "    parser.add_argument(\"--step_per_collect\", type=int, default=100) \n",
    "    parser.add_argument(\"--architecture\", type=int, default=[64, 64])\n",
    "    parser.add_argument(\"--backbone_out_dim\", type=int, default=64)\n",
    "\n",
    "    return parser.parse_known_args()[0]\n",
    "\n",
    "\n",
    "def create_env(kwargs1, kwargs2, max_t=50000, min_a=-1., max_a=1.):\n",
    "    \"\"\"\n",
    "    creates the environemnt and applyes wrappers to action and\n",
    "    observations space and sets time limit.\n",
    "    \"\"\"\n",
    "    env = KolmogorovEnvironment(kwargs1, kwargs2)\n",
    "    env = TimeLimit(env, max_episode_steps=max_t)\n",
    "    env = RescaleAction(env, min_action=min_a, max_action=max_a)\n",
    "    env = TransformObservation(env, lambda obs: (obs/20))\n",
    "    return env\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "\n",
    "    def __init__(self, out_size=64, device=\"cpu\"):\n",
    "        super(Backbone, self).__init__()\n",
    "        \n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 2, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(2, 4, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(4, 8, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        \n",
    "        ### Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(True),\n",
    "            #nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, out_size),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        \n",
    "    #def forward(self, x):\n",
    "    #    x = x.reshape(x.shape[0],1,128,128)\n",
    "    #    x = self.encoder_cnn(x)\n",
    "    #    x = x.reshape(x.shape[0], -1)\n",
    "    #    x = self.encoder_lin(x)\n",
    "    #    return x\n",
    "\n",
    "    def forward(self, obs, state=None, info={}):\n",
    "        if not isinstance(obs, torch.Tensor):\n",
    "            obs = torch.tensor(obs, dtype=torch.float, device=device)\n",
    "        batch = obs.shape[0]\n",
    "\n",
    "        obs = self.encoder_cnn(obs.reshape(batch, 1, 128, 128))\n",
    "        obs = obs.reshape(batch, -1)\n",
    "        logits = self.encoder_lin(obs)\n",
    "\n",
    "        return logits, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8e84131970>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#######################################################################################################\n",
    "####### setup stuff *##################################################################################\n",
    "#######################################################################################################\n",
    "args = get_args()\n",
    "# seed\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "#restrict_to_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m_prime = 31232.0, end time = 31232 steps, T=355, io_rate = 64.0, Number of outputs = 490.0\n",
      "m_prime = 31232.0, end time = 31232 steps, T=355, io_rate = 64.0, Number of outputs = 490.0\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################\n",
    "####### environments ##################################################################################\n",
    "#######################################################################################################\n",
    "u0_path = \"/home/pfischer/XLB/vel_init/velocity_burn_in_1806594.npy\" #4096x4096 simulation\n",
    "rho0_path = \"/home/pfischer/XLB/vel_init/density_burn_in_1806594.npy\" #4096x4096 simulation\n",
    "kwargs1, T1,_,_ = get_kwargs(u0_path=u0_path, rho0_path=rho0_path, lamb=1) #cgs \n",
    "kwargs2, T2,_,_ = get_kwargs(u0_path=u0_path, rho0_path=rho0_path, lamb=1) #fgs\n",
    "#check if cgs time is a factor of fgs time\n",
    "assert (T2%T1 == 0)\n",
    "env = create_env(kwargs1, kwargs2, max_t=T1)\n",
    "train_env = DummyVectorEnv([lambda: create_env(kwargs1, kwargs2, max_t=T1) for _ in range(args.train_num)])\n",
    "test_env = DummyVectorEnv([lambda: create_env(kwargs1, kwargs2, max_t=T1) for _ in range(args.test_num)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.shape)\n",
    "print(env.action_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Policy\n",
    "assert env.observation_space.shape is not None  # for mypy\n",
    "assert env.action_space.shape is not None\n",
    "\n",
    "net = Net(state_shape=env.observation_space.shape, hidden_sizes=args.architecture, device=device).to(device)\n",
    "#net = Backbone(out_size=args.backbone_out_dim, device=device).to(device)\n",
    "#net = Net1(state_shape=env.observation_space.shape, action_shape=(64,)).to(device)\n",
    "actor = ActorProb(preprocess_net=net, action_shape=env.action_space.shape, max_action=1,\n",
    "                 preprocess_net_output_dim=args.backbone_out_dim, device=device).to(device)\n",
    "critic = Critic(preprocess_net=net, preprocess_net_output_dim=args.backbone_out_dim, device=device).to(device)\n",
    "actor_critic = ActorCritic(actor=actor, critic=critic)\n",
    "optim = torch.optim.Adam(actor_critic.parameters(), lr=args.lr)\n",
    "dist = torch.distributions.Normal\n",
    "policy = PPOPolicy(\n",
    "    actor=actor,\n",
    "    critic=critic,\n",
    "    optim=optim,\n",
    "    dist_fn=dist,\n",
    "    action_space=env.action_space,\n",
    "    deterministic_eval=True,\n",
    "    action_scaling=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collectors\n",
    "train_collector = Collector(\n",
    "    policy=policy,\n",
    "    env=train_env,\n",
    "    buffer=VectorReplayBuffer(args.buffer_size, len(train_env)),\n",
    ")\n",
    "test_collector = Collector(policy=policy, env=test_env)\n",
    "train_collector.reset()\n",
    "test_collector.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Trainer\n",
    "trainer = OnpolicyTrainer(\n",
    "    policy=policy,\n",
    "    train_collector=train_collector,\n",
    "    test_collector=test_collector,\n",
    "    max_epoch=args.max_epoch,\n",
    "    step_per_epoch=args.step_per_epoch,\n",
    "    repeat_per_collect=args.repeat_per_collect,             \n",
    "    episode_per_test=args.episode_per_test,\n",
    "    batch_size=args.batch_size,\n",
    "    step_per_collect=args.step_per_collect,\n",
    "    #stop_fn=lambda mean_reward: mean_reward >= args.reward_threshold,\n",
    "    #save_checkpoint_fn=checkpoint_fn,\n",
    "    #logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #1: 1001it [00:06, 143.56it/s, env_step=1000, len=994, loss=30.446, loss/clip=0.005, loss/ent=1.405, loss/vf=60.911, n/ep=1, n/st=100, rew=980.59]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: test_reward: 3446.459598 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #2: 1001it [00:08, 114.59it/s, env_step=2000, len=134, loss=1.352, loss/clip=-0.002, loss/ent=1.407, loss/vf=2.734, n/ep=0, n/st=100, rew=133.30]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: test_reward: 4289.824106 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #3: 1001it [00:06, 154.91it/s, env_step=3000, len=994, loss=1.063, loss/clip=-0.004, loss/ent=1.425, loss/vf=2.163, n/ep=0, n/st=100, rew=980.59]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: test_reward: 1329.896208 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #4: 1001it [00:04, 230.52it/s, env_step=4000, len=994, loss=2.317, loss/clip=0.001, loss/ent=1.433, loss/vf=4.662, n/ep=0, n/st=100, rew=980.59]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: test_reward: 414.719675 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #5: 1001it [00:06, 150.96it/s, env_step=5000, len=2154, loss=2.552, loss/clip=-0.001, loss/ent=1.403, loss/vf=5.134, n/ep=0, n/st=100, rew=2123.97]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: test_reward: 93.498488 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #6: 1001it [00:04, 235.92it/s, env_step=6000, len=2154, loss=0.891, loss/clip=-0.000, loss/ent=1.432, loss/vf=1.812, n/ep=0, n/st=100, rew=2123.97]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: test_reward: 91.482476 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #7: 1001it [00:04, 244.99it/s, env_step=7000, len=2154, loss=1.501, loss/clip=-0.000, loss/ent=1.433, loss/vf=3.030, n/ep=0, n/st=100, rew=2123.97]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: test_reward: 91.481917 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #8: 1001it [00:04, 239.15it/s, env_step=8000, len=2154, loss=1.392, loss/clip=-0.000, loss/ent=1.452, loss/vf=2.813, n/ep=0, n/st=100, rew=2123.97]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: test_reward: 91.481917 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #9: 1001it [00:08, 121.36it/s, env_step=9000, len=92, loss=0.481, loss/clip=-0.000, loss/ent=1.462, loss/vf=0.991, n/ep=0, n/st=100, rew=91.48]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: test_reward: 91.481965 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #10: 1001it [00:04, 249.58it/s, env_step=10000, len=92, loss=0.137, loss/clip=-0.000, loss/ent=1.462, loss/vf=0.304, n/ep=0, n/st=100, rew=91.48]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10: test_reward: 91.481949 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #11: 1001it [00:06, 163.14it/s, env_step=11000, len=1976, loss=0.094, loss/clip=-0.000, loss/ent=1.449, loss/vf=0.217, n/ep=0, n/st=100, rew=1948.74]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11: test_reward: 91.481965 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #12: 1001it [00:03, 252.10it/s, env_step=12000, len=1976, loss=0.436, loss/clip=-0.000, loss/ent=1.481, loss/vf=0.901, n/ep=0, n/st=100, rew=1948.74]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12: test_reward: 91.481933 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #13: 1001it [00:06, 160.73it/s, env_step=13000, len=2003, loss=0.287, loss/clip=-0.000, loss/ent=1.520, loss/vf=0.605, n/ep=0, n/st=100, rew=1975.34]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13: test_reward: 91.481965 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #14: 1001it [00:04, 248.51it/s, env_step=14000, len=2003, loss=0.323, loss/clip=-0.000, loss/ent=1.494, loss/vf=0.677, n/ep=0, n/st=100, rew=1975.34]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14: test_reward: 91.481949 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #15: 1001it [00:04, 247.30it/s, env_step=15000, len=2003, loss=1.196, loss/clip=-0.000, loss/ent=1.477, loss/vf=2.422, n/ep=0, n/st=100, rew=1975.34]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #15: test_reward: 91.481917 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #16: 1001it [00:04, 245.79it/s, env_step=16000, len=2003, loss=0.719, loss/clip=-0.000, loss/ent=1.465, loss/vf=1.469, n/ep=0, n/st=100, rew=1975.34]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #16: test_reward: 91.481997 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #17: 1001it [00:12, 79.70it/s, env_step=17000, len=92, loss=177.234, loss/clip=-0.000, loss/ent=1.476, loss/vf=354.498, n/ep=2, n/st=100, rew=91.48]                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #17: test_reward: 91.482381 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #18: 1001it [00:08, 120.95it/s, env_step=18000, len=92, loss=4.728, loss/clip=-0.000, loss/ent=1.506, loss/vf=9.486, n/ep=0, n/st=100, rew=91.48]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #18: test_reward: 91.482045 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #19: 1001it [00:04, 242.72it/s, env_step=19000, len=92, loss=0.208, loss/clip=-0.001, loss/ent=1.540, loss/vf=0.448, n/ep=0, n/st=100, rew=91.48]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #19: test_reward: 91.495687 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch #20: 1001it [00:04, 248.18it/s, env_step=20000, len=92, loss=0.144, loss/clip=-0.001, loss/ent=1.536, loss/vf=0.321, n/ep=0, n/st=100, rew=91.48]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #20: test_reward: 91.481917 ± 0.000000, best_reward: 5167.335735 ± 0.000000 in #0\n"
     ]
    }
   ],
   "source": [
    "result = trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#steps = 92, Total Reward = 91.48191716757027\n"
     ]
    }
   ],
   "source": [
    "#play one episode and record statistics\n",
    "reward = 0\n",
    "step = 0\n",
    "obs ,inf = env.reset()\n",
    "policy.eval()\n",
    "episode_is_over = False\n",
    "#print(omg, env.unwrapped.fgs.omega, env.unwrapped.cgs.omega)\n",
    "while not episode_is_over:\n",
    "\n",
    "    action = policy(Batch(obs=np.array([obs]), info=inf)).act[0]\n",
    "    obs, rew, terminated, truncated, inf = env.step(action.detach().cpu().numpy())\n",
    "    #obs, rew, terminated, truncated, inf = env.step(-0.2)\n",
    "    reward += rew\n",
    "    step += 1\n",
    "    if terminated or truncated:\n",
    "        episode_is_over = True\n",
    "\n",
    "    if step%250 == 0:\n",
    "        ac = action.detach().cpu().numpy()[0]\n",
    "        a = 0.98\n",
    "        b = 1.02\n",
    "        scaled_ac = a + 0.5*(b-a)*(ac+1)\n",
    "        print(f\"action = {ac}; omega_cgs = {env.unwrapped.cgs.omega}; omega2 = {env.unwrapped.fgs.omega}; rescaled action = {scaled_ac*env.unwrapped.fgs.omega}\")\n",
    "        env.render()\n",
    "\n",
    "print(f\"#steps = {step}, Total Reward = {reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlb2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
